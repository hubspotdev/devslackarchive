[
  {
    "text": "Hi SEO enthusiasts!\nI am having an issue with one of my clientâ€™s websites.\nIt does not appear on Google results AT ALL! When I run a lighthouse analysis, it says that i have\n```x-robots-tag: none```\nBut I cannot seem to find where that is.\nI have robots.txt set up right as seen in the photos attached. Any guidance would be appreciated!",
    "time_stamp": "2023-03-07 12:37:59",
    "reply_count": 4,
    "reply_users_count": 2,
    "replies": [
      {
        "time_stamp": "2023-03-07 13:52:01"
      },
      {
        "time_stamp": "2023-03-07 18:00:30"
      },
      {
        "time_stamp": "2023-03-07 18:02:24"
      },
      {
        "time_stamp": "2023-03-08 07:13:35"
      }
    ]
  },
  {
    "poster": {
      "poster_name": "Maxwell Brosofsky",
      "poster_handle": "mbrosofsky"
    },
    "time_stamp": "2023-03-07 13:52:01",
    "edited": {
      "time_stamp": "2023-03-07 13:54:34"
    },
    "text": "that looks like it could be coming from the domain's CSP?\n\nSettings &gt; Website &gt; Domains and URLS &gt; Click Edit (next to the domain you're looking at in the examples) &gt; Update Domain Security Settings, look for the X-Robots-Tag either in a checkbox, or within the \"policy directives\" Under \"Content Security Policy\"\n\n<https://knowledge.HubSpot.com/domains-and-urls/ssl-and-domain-security-in-HubSpot#additional-domain-security-settings-cms-hub-only>"
  },
  {
    "text": "Thanks Maxwell!\nI will read more on that, but i believe I figured it out.\nI have not connected the domain with HubSpot yet, since we needed to partially migrate the site (one page at time). Therefore we were redirecting every new page to its new url.\nToday I learned that <http://hs-sites.com|hs-sites.com>, is only used for testing, and cannot be crawled by search engines.",
    "time_stamp": "2023-03-07 18:00:30"
  },
  {
    "poster": {
      "poster_name": "Afron Orana",
      "poster_handle": "afron.orana"
    },
    "time_stamp": "2023-03-07 18:02:24",
    "text": "Now I am not 100% sure that this will solve the issue, since we used masked redirects and there is no indication of the error dispalyed i the lighthouse but lets see"
  }
]